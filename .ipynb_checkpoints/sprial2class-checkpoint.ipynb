{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from sklearn.metrics import classification_report#这个包是评价报告\n",
    "from sklearn.model_selection import train_test_split\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1801, 2), (201, 2), (1801, 1), (201, 1))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"spiral_data/2class.txt\",delimiter=\" \",names=[\"x1\",\"x2\",\"y\"])\n",
    "x1 = df[\"x1\"]\n",
    "x2 = df[\"x2\"]\n",
    "X_train = np.array(df[[\"x1\",\"x2\"]])\n",
    "y_train = np.array(df[\"y\"]).reshape([-1,1])\n",
    "X_train,X_test,y_train,y_test = train_test_split(X_train,y_train,test_size=0.1,random_state=4)\n",
    "X_train.shape,X_test.shape,y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.36752, -0.05585]), array([1]))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0],y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 初始化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 2\n",
    "hidden_size = 50\n",
    "output_size = 1\n",
    "std = 1\n",
    "\n",
    "# rand函数根据给定维度生成[0,1)之间的数据，shape(input_size, hidden_size)\n",
    "W1 = std * np.random.randn(input_size, hidden_size)   #(2,10)\n",
    "b1 = np.zeros((1, hidden_size))                       #(1,10)\n",
    "W2 = std * np.random.randn(hidden_size,output_size)   #(10,1)\n",
    "b2 = np.zeros((1, output_size))                       #(1,1)\n",
    "\n",
    "params = {}\n",
    "params[\"W1\"] = W1\n",
    "params[\"b1\"] = b1\n",
    "params[\"W2\"] = W2\n",
    "params[\"b2\"] = b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def relu(x):\n",
    "    return np.maximum(0,x)\n",
    "\n",
    "def sigmoid_gradient(z):\n",
    "    return np.multiply(sigmoid(z), 1 - sigmoid(z))\n",
    "\n",
    "# ReLU(x)′={0,ifx<0; 1,ifx>0}\n",
    "def relu_gradient(x):\n",
    "    x[x<0] = 0\n",
    "    x[x>0] = 1\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(params,X):\n",
    "    z1 = np.dot(X,params[\"W1\"]) + params[\"b1\"]    # (4*2)                      \n",
    "    a1 = sigmoid(z1)                 # (4*10)    \n",
    "    z2 = np.dot(a1,params[\"W2\"]) + params[\"b2\"]     # (4*1)\n",
    "    a2 = sigmoid(z2)     # (4*1)\n",
    "    return z1,a1,z2,a2\n",
    "z1,a1,z2,a2 = forward_propagation(params,X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9380800984962432"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def computeLoss(y,t): # y->predict value t->true value\n",
    "#     return -np.sum(t*np.log(y+1e-5) + (1-t)*np.log(1-y+1e-5))/len(y)\n",
    "    return -np.mean(t*np.log(y+1e-5) + (1-t)*np.log(1-y+1e-5))\n",
    "computeLoss(a2,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1801, 50), (1801, 50), (1801, 1), (1801, 1))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z1.shape,a1.shape,z2.shape,a2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0: loss 0.159957 acc 0.950583\n",
      "iteration 1000: loss 0.157335 acc 0.952804\n",
      "iteration 2000: loss 0.154683 acc 0.953914\n",
      "iteration 3000: loss 0.151962 acc 0.955025\n",
      "iteration 4000: loss 0.149083 acc 0.956691\n",
      "iteration 5000: loss 0.145818 acc 0.957801\n",
      "iteration 6000: loss 0.142088 acc 0.959467\n",
      "iteration 7000: loss 0.138524 acc 0.960577\n",
      "iteration 8000: loss 0.135175 acc 0.962243\n",
      "iteration 9000: loss 0.131949 acc 0.964464\n",
      "iteration 10000: loss 0.128822 acc 0.966130\n",
      "iteration 11000: loss 0.125766 acc 0.966685\n",
      "iteration 12000: loss 0.122730 acc 0.968906\n",
      "iteration 13000: loss 0.119605 acc 0.970017\n",
      "iteration 14000: loss 0.116248 acc 0.972238\n",
      "iteration 15000: loss 0.112716 acc 0.972793\n",
      "iteration 16000: loss 0.109338 acc 0.974459\n",
      "iteration 17000: loss 0.106219 acc 0.977790\n",
      "iteration 18000: loss 0.103270 acc 0.977235\n",
      "iteration 19000: loss 0.100403 acc 0.977790\n",
      "iteration 20000: loss 0.097565 acc 0.978345\n",
      "iteration 21000: loss 0.094730 acc 0.978345\n",
      "iteration 22000: loss 0.091906 acc 0.980011\n",
      "iteration 23000: loss 0.089137 acc 0.982232\n",
      "iteration 24000: loss 0.086479 acc 0.984453\n",
      "iteration 25000: loss 0.083970 acc 0.987229\n",
      "iteration 26000: loss 0.081623 acc 0.987785\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-cc77061aade2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0ma2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma2\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0ma2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ma2\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m1000\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"iteration %d: loss %f acc %f\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mmean\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mmean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m   3255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3256\u001b[0m     return _methods._mean(a, axis=axis, dtype=dtype,\n\u001b[0;32m-> 3257\u001b[0;31m                           out=out, **kwargs)\n\u001b[0m\u001b[1;32m   3258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minteger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 146\u001b[0;31m             \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'f8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    147\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m             \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'f4'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "alpha = 0.5\n",
    "m = X_train.shape[0]\n",
    "iterations = 50000    \n",
    "\n",
    "for i in range(iterations):\n",
    "    z1,a1,z2,a2 = forward_propagation(params,X_train)\n",
    "    dz2 = a2 - y_train  # (4,1)\n",
    "    dw2 = (1/m)*np.dot(a1.T,dz2) # (10,1)\n",
    "    db2 = (1/m)*np.sum(dz2,axis=0,keepdims=True) # (1,1)\n",
    "    dz1 = np.dot(dz2,params[\"W2\"].T)*sigmoid_gradient(z1) # (4,10)\n",
    "    dw1 = (1/m)*np.dot(X_train.T,dz1) # (2,10)\n",
    "    db1 = (1/m)*np.sum(dz1,axis=0,keepdims=True) # (1,10)\n",
    "    loss = computeLoss(a2,y_train)\n",
    "    a2[a2 <= 0.5] = 0\n",
    "    a2[a2 > 0.5] = 1\n",
    "    acc = np.mean(a2 == y_train)\n",
    "    if i % 1000 == 0:\n",
    "        print(\"iteration %d: loss %f acc %f\" % (i, loss,acc))\n",
    "#         print(a2)\n",
    "#         print(params)\n",
    "        \n",
    "    params[\"W1\"] += -alpha * dw1  # (2,10)\n",
    "    params[\"b1\"] += -alpha * db1  # (1,10)\n",
    "    params[\"W2\"] += -alpha * dw2  # (10,1)\n",
    "    params[\"b2\"] += -alpha * db2  # (1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
